{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "vader_lexicon = analyzer.lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"train.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_test = \"test.csv\"\n",
    "df_testset = pd.read_csv(file_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Vader Sentiment\"] != \"Neutral\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Vader_Binary_Sentiment\"] = df[\"Vader Sentiment\"].map({\"Positive\": 1, \"Negative\": 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentence_length\"] = df[\"cleanText\"].str.split().str.len()\n",
    "max_length = df[\"sentence_length\"].max()  # To find the longest sentence \n",
    "\n",
    "print(f\"Max length: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testset[\"sentence_length\"] = df_testset[\"cleanText\"].str.split().str.len()\n",
    "max_length_test = df_testset[\"sentence_length\"].max()  # To find the longest sentence \n",
    "\n",
    "print(f\"Max length: {max_length_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vader_scores(sentence):\n",
    "    words = sentence.split()\n",
    "    scores = [vader_lexicon.get(word.lower(), 0) for word in words]  # Convert words to lowercase\n",
    "    \n",
    "    # Padding to check that all arrays have the same length\n",
    "    if len(scores) < max_length:\n",
    "        scores.extend([0] * (max_length - len(scores)))  # Padding\n",
    "    else:\n",
    "        scores = scores[:max_length]  \n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment_vector\"] = df[\"cleanText\"].apply(sentence_to_vader_scores)\n",
    "df_testset[\"sentiment_vector\"] = df_testset[\"cleanText\"].apply(sentence_to_vader_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"desc_id\", \"sentiment_vector\",\"Vader_Binary_Sentiment\"]].to_csv(\"processed_train.csv\",index=False)\n",
    "df_testset[[\"desc_id\", \"sentiment_vector\"]].to_csv(\"processed_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the processed dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"processed_train.csv\"\n",
    "df_processed = pd.read_csv(file_path)\n",
    "df_test=pd.read_csv(\"processed_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to clean and convert sentiment_vector to a list of floats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentiment_array(array_str):\n",
    "    # Clean and split the string into numbers\n",
    "    array_str = array_str.replace(\n",
    "        \"\\n\", \" \").replace(\",\", \" \").strip(\"[], \")\n",
    "    array_list = [float(num) for num in array_str.split() if num]\n",
    "\n",
    "    # Array should be exactly 236\n",
    "    array_list.extend([0] * (236 - len(array_list)))\n",
    "    return np.array(array_list[:236], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed[\"sentiment_vector\"] = df_processed[\"sentiment_vector\"].apply(clean_sentiment_array)\n",
    "\n",
    "df_test[\"sentiment_vector\"] = df_test[\"sentiment_vector\"].apply(clean_sentiment_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Extract features (X) and labels (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(df_processed[\"sentiment_vector\"].values)\n",
    "y = df_processed[\"Vader_Binary_Sentiment\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and validation sets (80%-20%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Feature scaling (Standardization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------\n",
    "# Logistic Regression Model\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Weights with the He Initialization\n",
    "def initialize_weights_he(n_features):\n",
    "    weights = np.random.randn(n_features) * np.sqrt(2.0 / n_features)\n",
    "    bias = 0\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activation Function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y_true, y_pred, weights, lamb):\n",
    "    m = len(y_true)\n",
    "    cross_entropy_loss = -(1/m) * np.sum(y_true * np.log(y_pred + 1e-9) + (1 - y_true) * np.log(1 - y_pred + 1e-9))\n",
    "    l2_loss = (lamb / (2 * m)) * np.sum(weights**2)  # L2 regularization\n",
    "    return cross_entropy_loss + l2_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam_optimizer(X, y, weights, bias, learning_rate, epochs, lamb, batch_size, beta1=0.9, beta2=0.999, epsilon=1e-8, early_stopping_patience=5):\n",
    "    m = X.shape[0]\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # Adam optimization variables\n",
    "    m_w, v_w = np.zeros_like(weights), np.zeros_like(weights)\n",
    "    m_b, v_b = 0, 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        indices = np.random.permutation(m)\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "\n",
    "        for i in range(0, m, batch_size):\n",
    "            X_batch = X_shuffled[i:i + batch_size]\n",
    "            y_batch = y_shuffled[i:i + batch_size]\n",
    "\n",
    "            # Forward pass\n",
    "            linear_model = np.dot(X_batch, weights) + bias\n",
    "            y_pred = sigmoid(linear_model)\n",
    "\n",
    "            #gradients Using L2 regularization\n",
    "            dw = (1/batch_size) * np.dot(X_batch.T, (y_pred - y_batch)) + (lamb / batch_size) * weights\n",
    "            db = (1/batch_size) * np.sum(y_pred - y_batch)\n",
    "\n",
    "            # Adam Optimizer Updates\n",
    "            m_w = beta1 * m_w + (1 - beta1) * dw\n",
    "            v_w = beta2 * v_w + (1 - beta2) * (dw ** 2)\n",
    "\n",
    "\n",
    "            m_b = beta1 * m_b + (1 - beta1) * db\n",
    "            v_b = beta2 * v_b + (1 - beta2) * (db ** 2)\n",
    "\n",
    "            m_w_hat = m_w / (1 - beta1 ** (epoch + 1))\n",
    "            v_w_hat = v_w / (1 - beta2 ** (epoch + 1))\n",
    "\n",
    "            m_b_hat = m_b / (1 - beta1 ** (epoch + 1))\n",
    "            v_b_hat = v_b / (1 - beta2 ** (epoch + 1))\n",
    "\n",
    "            weights -= learning_rate * m_w_hat / (np.sqrt(v_w_hat) + epsilon)\n",
    "            bias -= learning_rate * m_b_hat / (np.sqrt(v_b_hat) + epsilon)\n",
    "\n",
    "        # Validation loss and accuracy\n",
    "        y_val_pred = sigmoid(np.dot(X_val_scaled, weights) + bias)\n",
    "        val_loss = compute_loss(y_val, y_val_pred, weights, lamb)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        y_val_pred_binary = (y_val_pred >= 0.5).astype(int)\n",
    "        val_accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    print(f\"Final Validation Accuracy: {val_accuracies[-1]:.4f}\")\n",
    "    return weights, bias, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------\n",
    "# Train the Logistic Regression Model\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb = 0.0001\n",
    "learning_rate = 0.6\n",
    "batch_size = 1024\n",
    "epochs = 500\n",
    "early_stopping_patience = 10\n",
    "weights, bias = initialize_weights_he(X_train_scaled.shape[1])\n",
    "weights, bias, _, _ = adam_optimizer(X_train_scaled, y_train, weights, bias, learning_rate, epochs, lamb, batch_size, early_stopping_patience=early_stopping_patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model weights and bias in a CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.DataFrame(weights, columns=[\"weights\"])  \n",
    "model_df[\"bias\"] = bias\n",
    "model_df.to_csv(\"model_weights_bias.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.vstack(df_test[\"sentiment_vector\"].values)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_test_pred = sigmoid(np.dot(X_test_scaled, weights) + bias)\n",
    "y_test_pred_binary = (y_test_pred >= 0.5).astype(int)\n",
    "\n",
    "submission_df = pd.DataFrame({\"id\": df_test.get(\"id\", np.arange(len(y_test_pred_binary))), \"Vader_Binary_Sentiment\": y_test_pred_binary})\n",
    "submission_df.to_csv(\"sub.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
